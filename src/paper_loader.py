# src/paper_loader.py
"""
è®ºæ–‡åŠ è½½ä¸Žå…ƒæ•°æ®æå–
"""
import os
import re
from datetime import datetime
from typing import Dict, List, Optional
from dataclasses import dataclass, asdict
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_text_splitters import RecursiveCharacterTextSplitter
from .config import config


@dataclass
class PaperMetadata:
    """è®ºæ–‡å…ƒæ•°æ®"""
    title: str
    authors: List[str]
    abstract: str
    year: Optional[int] = None
    venue: Optional[str] = None  # å‘è¡¨ä¼šè®®/æœŸåˆŠ
    keywords: List[str] = None
    file_path: str = ""
    added_date: str = ""

    def __post_init__(self):
        if not self.added_date:
            self.added_date = datetime.now().strftime("%Y-%m-%d %H:%M")
        if self.keywords is None:
            self.keywords = []


class PaperLoader:
    """è®ºæ–‡åŠ è½½å™¨"""

    def __init__(self):
        self.llm = ChatOllama(model=config.LLM_MODEL, temperature=0)
        self.splitter = RecursiveCharacterTextSplitter(
            chunk_size=config.CHUNK_SIZE,
            chunk_overlap=config.CHUNK_OVERLAP,
            separators=["\n\n", "\n", ". ", " ", ""]
        )

        # å…ƒæ•°æ®æå– Prompt
        self.metadata_prompt = ChatPromptTemplate.from_template(
            """ä»Žä»¥ä¸‹è®ºæ–‡å†…å®¹ä¸­æå–å…ƒæ•°æ®ä¿¡æ¯ã€‚

ã€è®ºæ–‡å†…å®¹ï¼ˆå‰3é¡µï¼‰ã€‘
{content}

è¯·æå–ä»¥ä¸‹ä¿¡æ¯ï¼Œä»¥ JSON æ ¼å¼è¾“å‡ºï¼š
{{
    "title": "è®ºæ–‡æ ‡é¢˜",
    "authors": ["ä½œè€…1", "ä½œè€…2"],
    "abstract": "æ‘˜è¦å†…å®¹ï¼ˆå¦‚æžœèƒ½æ‰¾åˆ°ï¼‰",
    "year": å‘è¡¨å¹´ä»½ï¼ˆæ•°å­—ï¼Œå¦‚ 2023ï¼‰,
    "venue": "å‘è¡¨ä¼šè®®æˆ–æœŸåˆŠåç§°",
    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3"]
}}

æ³¨æ„ï¼š
- å¦‚æžœæŸä¸ªå­—æ®µæ‰¾ä¸åˆ°ï¼Œè®¾ä¸º null
- keywords è¯·æ ¹æ®è®ºæ–‡å†…å®¹è‡ªåŠ¨æå– 3-5 ä¸ªå…³é”®è¯
- åªè¾“å‡º JSONï¼Œä¸è¦å…¶ä»–å†…å®¹

JSON è¾“å‡ºï¼š"""
        )

    def load_pdf(self, file_path: str) -> tuple[List, PaperMetadata]:
        """
        åŠ è½½ PDF è®ºæ–‡
        è¿”å›žï¼š(æ–‡æ¡£å—åˆ—è¡¨, å…ƒæ•°æ®)
        """
        print(f"ðŸ“„ åŠ è½½è®ºæ–‡: {file_path}")

        # 1. åŠ è½½ PDF
        loader = PyPDFLoader(file_path)
        pages = loader.load()

        if not pages:
            raise ValueError(f"æ— æ³•åŠ è½½ PDF: {file_path}")

        print(f"   å…± {len(pages)} é¡µ")

        # 2.  æå–å…ƒæ•°æ®ï¼ˆç”¨å‰3é¡µçš„å†…å®¹ï¼‰
        first_pages_content = "\n".join([
            pages[i].page_content for i in range(min(3, len(pages)))
        ])
        metadata = self._extract_metadata(first_pages_content, file_path)

        # 3. åˆ‡åˆ†æ–‡æ¡£
        chunks = self.splitter.split_documents(pages)
        print(f"   åˆ‡åˆ†ä¸º {len(chunks)} ä¸ªæ–‡æœ¬å—")

        # 4. ä¸ºæ¯ä¸ª chunk æ·»åŠ å…ƒæ•°æ®
        for chunk in chunks:
            chunk.metadata.update({
                "title": metadata.title,
                "authors": ", ".join(metadata.authors),
                "year": metadata.year,
                "venue": metadata.venue,
                "keywords": ", ".join(metadata.keywords),
                "file_path": file_path
            })

        return chunks, metadata

    def _extract_metadata(self, content: str, file_path: str) -> PaperMetadata:
        """ä½¿ç”¨ LLM æå–è®ºæ–‡å…ƒæ•°æ®"""
        try:
            chain = self.metadata_prompt | self.llm | JsonOutputParser()
            result = chain.invoke({"content": content[:8000]})  # é™åˆ¶é•¿åº¦

            return PaperMetadata(
                title=result.get("title", "Unknown Title"),
                authors=result.get("authors", ["Unknown"]),
                abstract=result.get("abstract", ""),
                year=result.get("year"),
                venue=result.get("venue"),
                keywords=result.get("keywords", []),
                file_path=file_path
            )
        except Exception as e:
            print(f"   âš ï¸å…ƒæ•°æ®æå–å¤±è´¥: {e}")
            # ä»Žæ–‡ä»¶åçŒœæµ‹æ ‡é¢˜
            filename = os.path.basename(file_path)
            title = os.path.splitext(filename)[0].replace("_", " ")
            return PaperMetadata(
                title=title,
                authors=["Unknown"],
                abstract="",
                file_path=file_path
            )

    def load_text_note(self, content: str, title: str) -> List:
        """åŠ è½½æ–‡æœ¬ç¬”è®°"""
        from langchain_core.documents import Document

        doc = Document(
            page_content=content,
            metadata={
                "title": title,
                "type": "note",
                "added_date": datetime.now().strftime("%Y-%m-%d %H:%M")
            }
        )
        return self.splitter.split_documents([doc])